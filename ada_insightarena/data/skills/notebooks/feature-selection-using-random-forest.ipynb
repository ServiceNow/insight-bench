{"cells":[{"metadata":{"_uuid":"7bc28d3a4c4b43d1e7f4a66ca04823c77f5e6c64"},"cell_type":"markdown","source":"This tutorial is made to learn about feature selection in random forest to increase the accuracy of your random forest classifier."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"**CREATE THE DATA..**\nThe data used in this tutorial is from famous iris dataset.\nThe Iris target data contains 50 samples from three species of Iris, y and four feature variables, X."},{"metadata":{"trusted":true,"_uuid":"f5d21394d2ac208eaa7cb0dad1fe7afea1169f20"},"cell_type":"code","source":"# Load the iris dataset\niris = datasets.load_iris()\n\n# Create a list of feature names\nfeat_labels = ['Sepal Length','Sepal Width','Petal Length','Petal Width']\n\n# Create X from the features\nX = iris.data\n\n# Create y from output\ny = iris.target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a222276a867b65e056c763f19e39b38f753d067"},"cell_type":"code","source":"# View the features\nX[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b802a5d62ea17292449a24d2a06ff6cccb55b01f"},"cell_type":"code","source":"# View the target data\ny","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a22d1831e49b8ada3d1eaaf696e357fe3e2fe09c"},"cell_type":"markdown","source":"**Split The Data Into Training And Test Sets**"},{"metadata":{"trusted":true,"_uuid":"790c5577faaf75513d344867cc4b1645b0d19323"},"cell_type":"code","source":"# Split the data into 40% test and 60% training\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"85ce1efcb4c9ab02fee6d3ee677cae9facbb3bb0"},"cell_type":"markdown","source":"**Train A Random Forest Classifier**"},{"metadata":{"trusted":true,"_uuid":"816b0edcc81ebe63c50a2b56b3d377e7a59d1ea8"},"cell_type":"code","source":"# Create a random forest classifier\nclf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n\n# Train the classifier\nclf.fit(X_train, y_train)\n\n# Print the name and gini importance of each feature\nfor feature in zip(feat_labels, clf.feature_importances_):\n    print(feature)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e36ae0f1c5627cf8712b2c68e2cd2649d4953c23"},"cell_type":"markdown","source":"The scores above are the importance scores for each variable. There are two things to note. First, all the importance scores add up to 100%. Second, Petal Length and Petal Width are far more important than the other two features. Combined, Petal Length and Petal Width have an importance of ~0.86! Clearly these are the most importance features."},{"metadata":{"_uuid":"38cea98039852f3d1244befc1feb78e44cf4bab7"},"cell_type":"markdown","source":"**Identify And Select Most Important Features**"},{"metadata":{"trusted":true,"_uuid":"195b16158fbdc5c6fcd0b16ad815a032649277b3"},"cell_type":"code","source":"# Create a selector object that will use the random forest classifier to identify\n# features that have an importance of more than 0.15\nsfm = SelectFromModel(clf, threshold=0.15)\n\n# Train the selector\nsfm.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e0f560912909ba9aeee53baa2a9482ef0b97ddc"},"cell_type":"code","source":"# Print the names of the most important features\nfor feature_list_index in sfm.get_support(indices=True):\n    print(feat_labels[feature_list_index])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"909dc660bc3048086899f0d7a3ad828715d0ff76"},"cell_type":"markdown","source":"**Create A Data Subset With Only The Most Important Features\n**"},{"metadata":{"trusted":true,"_uuid":"b2d71f95cecc03ae3d7b6c4aa93bddf02f47b97e"},"cell_type":"code","source":"# Transform the data to create a new dataset containing only the most important features\n# Note: We have to apply the transform to both the training X and test X data.\nX_important_train = sfm.transform(X_train)\nX_important_test = sfm.transform(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"371df85095870a40f63eb01df73e0d408aefc1fe"},"cell_type":"markdown","source":"**Train A New Random Forest Classifier Using Only Most Important Features**"},{"metadata":{"trusted":true,"_uuid":"f2657dc4a681cff595d92eebcfd654bfa69b1452"},"cell_type":"code","source":"# Create a new random forest classifier for the most important features\nclf_important = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n\n# Train the new classifier on the new dataset containing the most important features\nclf_important.fit(X_important_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6d025c27a48097222140ecf47d8de8af0d1fc439"},"cell_type":"markdown","source":"**Compare The Accuracy Of Our Full Feature Classifier To Our Limited Feature Classifier**"},{"metadata":{"trusted":true,"_uuid":"f9b98da8dba8e5ddf2fe8b10dced5749b4eefc3c"},"cell_type":"code","source":"# Apply The Full Featured Classifier To The Test Data\ny_pred = clf.predict(X_test)\n\n# View The Accuracy Of Our Full Feature (4 Features) Model\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2872a2d6a682188694fe395a95772167cac4bb8"},"cell_type":"code","source":"# Apply The Full Featured Classifier To The Test Data\ny_important_pred = clf_important.predict(X_important_test)\n\n# View The Accuracy Of Our Limited Feature (2 Features) Model\naccuracy_score(y_test, y_important_pred)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"387395affc6ba35124ac9e83b7930d11cd4b500a"},"cell_type":"markdown","source":"**As can be seen by the accuracy scores, our original model which contained all four features is 93.3% accurate while the our ‘limited’ model which contained only two features is 90% accurate. Thus, for a small cost in accuracy we halved the number of features in the model.**"},{"metadata":{"trusted":true,"_uuid":"a478ddf9b9d0b41d49f1ef223b5b67c31355d060"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}